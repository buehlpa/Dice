{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train a model to predict what the single dice classes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230 images belonging to 6 classes.\n",
      "Found 55 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 4.3953 - accuracy: 0.2098 - val_loss: 4.1970 - val_accuracy: 0.2500\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.0744 - accuracy: 0.2323 - val_loss: 3.8341 - val_accuracy: 0.3438\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.7857 - accuracy: 0.2634 - val_loss: 3.6867 - val_accuracy: 0.1875\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.5482 - accuracy: 0.2525 - val_loss: 3.4087 - val_accuracy: 0.2188\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3.2803 - accuracy: 0.2768 - val_loss: 3.1393 - val_accuracy: 0.2812\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 3.0592 - accuracy: 0.3333 - val_loss: 2.9221 - val_accuracy: 0.4375\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8606 - accuracy: 0.3485 - val_loss: 2.7062 - val_accuracy: 0.4062\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6718 - accuracy: 0.3125 - val_loss: 2.5180 - val_accuracy: 0.3125\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.5125 - accuracy: 0.3795 - val_loss: 2.3160 - val_accuracy: 0.3438\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.3264 - accuracy: 0.4141 - val_loss: 2.2418 - val_accuracy: 0.5312\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1746 - accuracy: 0.4545 - val_loss: 1.9827 - val_accuracy: 0.5625\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0159 - accuracy: 0.4697 - val_loss: 1.9654 - val_accuracy: 0.4375\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8955 - accuracy: 0.4747 - val_loss: 1.7163 - val_accuracy: 0.4375\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7725 - accuracy: 0.5253 - val_loss: 1.6188 - val_accuracy: 0.6250\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.6616 - accuracy: 0.5606 - val_loss: 1.5109 - val_accuracy: 0.6562\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5826 - accuracy: 0.5960 - val_loss: 1.4277 - val_accuracy: 0.9062\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4909 - accuracy: 0.6717 - val_loss: 1.3061 - val_accuracy: 0.8125\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.5317 - accuracy: 0.5909 - val_loss: 1.3048 - val_accuracy: 0.7812\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4453 - accuracy: 0.6616 - val_loss: 1.2946 - val_accuracy: 0.7500\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.4535 - accuracy: 0.5909 - val_loss: 1.2432 - val_accuracy: 0.6562\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.3618 - accuracy: 0.6919 - val_loss: 1.1504 - val_accuracy: 0.9688\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3374 - accuracy: 0.6919 - val_loss: 1.1767 - val_accuracy: 0.8438\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2767 - accuracy: 0.6869 - val_loss: 1.1114 - val_accuracy: 0.9062\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.2530 - accuracy: 0.7222 - val_loss: 1.0524 - val_accuracy: 0.8125\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2155 - accuracy: 0.7374 - val_loss: 0.9821 - val_accuracy: 0.9375\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.1723 - accuracy: 0.7424 - val_loss: 0.9357 - val_accuracy: 0.9062\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.1178 - accuracy: 0.7323 - val_loss: 0.9306 - val_accuracy: 0.9062\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.1195 - accuracy: 0.7576 - val_loss: 0.8838 - val_accuracy: 0.8750\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0749 - accuracy: 0.7626 - val_loss: 0.8170 - val_accuracy: 0.9688\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0219 - accuracy: 0.7980 - val_loss: 0.7476 - val_accuracy: 0.9688\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9774 - accuracy: 0.8131 - val_loss: 0.8359 - val_accuracy: 0.9062\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9914 - accuracy: 0.8131 - val_loss: 0.8286 - val_accuracy: 0.9062\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0221 - accuracy: 0.7677 - val_loss: 0.6770 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0004 - accuracy: 0.7634 - val_loss: 0.6795 - val_accuracy: 0.9688\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9305 - accuracy: 0.7857 - val_loss: 0.8035 - val_accuracy: 0.9062\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9473 - accuracy: 0.8131 - val_loss: 0.8898 - val_accuracy: 0.8438\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9237 - accuracy: 0.8434 - val_loss: 0.7559 - val_accuracy: 0.8750\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8320 - accuracy: 0.8838 - val_loss: 0.6719 - val_accuracy: 0.9688\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9657 - accuracy: 0.8131 - val_loss: 0.7529 - val_accuracy: 0.9062\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9858 - accuracy: 0.7727 - val_loss: 0.6442 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9263 - accuracy: 0.8030 - val_loss: 0.7253 - val_accuracy: 0.8750\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8300 - accuracy: 0.8687 - val_loss: 0.7530 - val_accuracy: 0.9375\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8850 - accuracy: 0.8434 - val_loss: 0.5854 - val_accuracy: 0.9688\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8700 - accuracy: 0.8333 - val_loss: 0.7757 - val_accuracy: 0.9062\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8437 - accuracy: 0.8182 - val_loss: 0.6413 - val_accuracy: 0.9375\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7728 - accuracy: 0.8571 - val_loss: 0.7398 - val_accuracy: 0.8750\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8076 - accuracy: 0.8434 - val_loss: 0.5887 - val_accuracy: 0.9375\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8019 - accuracy: 0.8535 - val_loss: 0.6130 - val_accuracy: 0.9062\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7206 - accuracy: 0.8788 - val_loss: 0.5203 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7961 - accuracy: 0.8535 - val_loss: 0.5668 - val_accuracy: 0.9688\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7687 - accuracy: 0.8485 - val_loss: 0.6260 - val_accuracy: 0.9375\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8159 - accuracy: 0.8232 - val_loss: 0.6729 - val_accuracy: 0.9375\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7466 - accuracy: 0.8535 - val_loss: 0.5685 - val_accuracy: 0.9375\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7888 - accuracy: 0.8586 - val_loss: 0.5307 - val_accuracy: 0.9688\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7009 - accuracy: 0.8838 - val_loss: 0.5875 - val_accuracy: 0.9688\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6742 - accuracy: 0.9141 - val_loss: 0.4279 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6655 - accuracy: 0.8990 - val_loss: 0.5182 - val_accuracy: 0.9375\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7465 - accuracy: 0.8232 - val_loss: 0.5004 - val_accuracy: 0.9062\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7268 - accuracy: 0.8687 - val_loss: 0.5343 - val_accuracy: 0.9375\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7035 - accuracy: 0.8485 - val_loss: 0.4744 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6828 - accuracy: 0.8929 - val_loss: 0.4603 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.8687 - val_loss: 0.6230 - val_accuracy: 0.9375\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7623 - accuracy: 0.8333 - val_loss: 0.5961 - val_accuracy: 0.9062\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7117 - accuracy: 0.8384 - val_loss: 0.5426 - val_accuracy: 0.9062\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6954 - accuracy: 0.9141 - val_loss: 0.5582 - val_accuracy: 0.9688\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7110 - accuracy: 0.8535 - val_loss: 0.5750 - val_accuracy: 0.9375\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7204 - accuracy: 0.8737 - val_loss: 0.6409 - val_accuracy: 0.9375\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8038 - accuracy: 0.8131 - val_loss: 0.5282 - val_accuracy: 0.9375\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.8939 - val_loss: 0.5318 - val_accuracy: 0.9375\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6342 - accuracy: 0.9192 - val_loss: 0.5472 - val_accuracy: 0.9688\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6903 - accuracy: 0.8636 - val_loss: 0.6489 - val_accuracy: 0.9375\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6600 - accuracy: 0.9040 - val_loss: 0.4394 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6659 - accuracy: 0.8788 - val_loss: 0.5377 - val_accuracy: 0.9375\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.8889 - val_loss: 0.4790 - val_accuracy: 0.9375\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6721 - accuracy: 0.8616 - val_loss: 0.5599 - val_accuracy: 0.9062\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6665 - accuracy: 0.8838 - val_loss: 0.4171 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6329 - accuracy: 0.8838 - val_loss: 0.4241 - val_accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6425 - accuracy: 0.8838 - val_loss: 0.6012 - val_accuracy: 0.9375\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6353 - accuracy: 0.8737 - val_loss: 0.5785 - val_accuracy: 0.9375\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5924 - accuracy: 0.8889 - val_loss: 0.4183 - val_accuracy: 0.9688\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5921 - accuracy: 0.9152 - val_loss: 0.4988 - val_accuracy: 0.9688\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6271 - accuracy: 0.9141 - val_loss: 0.5090 - val_accuracy: 0.9375\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5699 - accuracy: 0.8889 - val_loss: 0.3516 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5852 - accuracy: 0.9141 - val_loss: 0.4885 - val_accuracy: 0.8750\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5928 - accuracy: 0.9040 - val_loss: 0.5864 - val_accuracy: 0.9062\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5643 - accuracy: 0.8990 - val_loss: 0.4125 - val_accuracy: 0.9688\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5770 - accuracy: 0.8939 - val_loss: 0.4645 - val_accuracy: 0.9375\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6120 - accuracy: 0.8838 - val_loss: 0.5337 - val_accuracy: 0.9375\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5715 - accuracy: 0.9040 - val_loss: 0.6186 - val_accuracy: 0.9375\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6048 - accuracy: 0.9040 - val_loss: 0.4152 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5507 - accuracy: 0.9040 - val_loss: 0.4121 - val_accuracy: 0.9688\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5315 - accuracy: 0.9192 - val_loss: 0.4813 - val_accuracy: 0.9375\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5531 - accuracy: 0.9040 - val_loss: 0.4578 - val_accuracy: 0.9375\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5598 - accuracy: 0.8884 - val_loss: 0.4489 - val_accuracy: 0.9062\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5600 - accuracy: 0.8788 - val_loss: 0.4323 - val_accuracy: 0.9375\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5896 - accuracy: 0.8661 - val_loss: 0.5734 - val_accuracy: 0.9062\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5912 - accuracy: 0.9091 - val_loss: 0.3382 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5799 - accuracy: 0.8939 - val_loss: 0.4084 - val_accuracy: 0.9688\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.9343 - val_loss: 0.4674 - val_accuracy: 0.9688\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5584 - accuracy: 0.8990 - val_loss: 0.5091 - val_accuracy: 0.9688\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5700 - accuracy: 0.8939 - val_loss: 0.4592 - val_accuracy: 0.9375\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6115 - accuracy: 0.8889 - val_loss: 0.3705 - val_accuracy: 0.9688\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5458 - accuracy: 0.8990 - val_loss: 0.5257 - val_accuracy: 0.9375\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4725 - accuracy: 0.9293 - val_loss: 0.3604 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5666 - accuracy: 0.8939 - val_loss: 0.4067 - val_accuracy: 0.9375\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5349 - accuracy: 0.9091 - val_loss: 0.4812 - val_accuracy: 0.8750\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5440 - accuracy: 0.9040 - val_loss: 0.4478 - val_accuracy: 0.9688\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5353 - accuracy: 0.8990 - val_loss: 0.5786 - val_accuracy: 0.8750\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.9141 - val_loss: 0.3612 - val_accuracy: 0.9688\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5315 - accuracy: 0.9192 - val_loss: 0.3225 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.9293 - val_loss: 0.5038 - val_accuracy: 0.8750\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4828 - accuracy: 0.9343 - val_loss: 0.3213 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4844 - accuracy: 0.9242 - val_loss: 0.3376 - val_accuracy: 0.9688\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5142 - accuracy: 0.9040 - val_loss: 0.3560 - val_accuracy: 0.9688\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.9091 - val_loss: 0.2971 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5014 - accuracy: 0.9293 - val_loss: 0.3741 - val_accuracy: 0.9375\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5605 - accuracy: 0.8737 - val_loss: 0.4438 - val_accuracy: 0.9688\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5312 - accuracy: 0.9040 - val_loss: 0.3196 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4468 - accuracy: 0.9152 - val_loss: 0.5067 - val_accuracy: 0.9062\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5126 - accuracy: 0.9062 - val_loss: 0.4304 - val_accuracy: 0.9375\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4669 - accuracy: 0.9192 - val_loss: 0.4409 - val_accuracy: 0.9375\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5021 - accuracy: 0.9141 - val_loss: 0.3805 - val_accuracy: 0.9375\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4244 - accuracy: 0.9394 - val_loss: 0.4868 - val_accuracy: 0.9062\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.9286 - val_loss: 0.3006 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 0.9062 - val_loss: 0.3770 - val_accuracy: 0.9688\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4465 - accuracy: 0.9343 - val_loss: 0.3236 - val_accuracy: 0.9688\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4566 - accuracy: 0.9343 - val_loss: 0.4408 - val_accuracy: 0.9062\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.9107 - val_loss: 0.4148 - val_accuracy: 0.9375\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4617 - accuracy: 0.9242 - val_loss: 0.3277 - val_accuracy: 0.9688\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.9495 - val_loss: 0.3143 - val_accuracy: 0.9688\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4363 - accuracy: 0.9375 - val_loss: 0.3644 - val_accuracy: 0.9688\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4764 - accuracy: 0.9242 - val_loss: 0.4108 - val_accuracy: 0.9375\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9343 - val_loss: 0.3547 - val_accuracy: 0.9375\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 0.9444 - val_loss: 0.3646 - val_accuracy: 0.9375\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4360 - accuracy: 0.9141 - val_loss: 0.3411 - val_accuracy: 0.9375\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4382 - accuracy: 0.9394 - val_loss: 0.2969 - val_accuracy: 0.9688\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4437 - accuracy: 0.9293 - val_loss: 0.3842 - val_accuracy: 0.9062\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4933 - accuracy: 0.9286 - val_loss: 0.3689 - val_accuracy: 0.9688\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4482 - accuracy: 0.9394 - val_loss: 0.4050 - val_accuracy: 0.9688\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.9091 - val_loss: 0.3615 - val_accuracy: 0.9375\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5238 - accuracy: 0.8889 - val_loss: 0.7333 - val_accuracy: 0.9062\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8889 - val_loss: 0.4687 - val_accuracy: 0.9688\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4121 - accuracy: 0.9596 - val_loss: 0.2864 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5100 - accuracy: 0.9293 - val_loss: 0.3788 - val_accuracy: 0.9062\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4425 - accuracy: 0.9293 - val_loss: 0.4132 - val_accuracy: 0.9062\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3859 - accuracy: 0.9394 - val_loss: 0.3010 - val_accuracy: 0.9688\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3844 - accuracy: 0.9343 - val_loss: 0.2861 - val_accuracy: 0.9688\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4401 - accuracy: 0.9242 - val_loss: 0.4299 - val_accuracy: 0.9375\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.9242 - val_loss: 0.3099 - val_accuracy: 0.9688\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4241 - accuracy: 0.9343 - val_loss: 0.4339 - val_accuracy: 0.8750\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3720 - accuracy: 0.9444 - val_loss: 0.2545 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4570 - accuracy: 0.9091 - val_loss: 0.4546 - val_accuracy: 0.9375\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4997 - accuracy: 0.9091 - val_loss: 0.5644 - val_accuracy: 0.8750\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4824 - accuracy: 0.9091 - val_loss: 0.4158 - val_accuracy: 0.9688\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.9091 - val_loss: 0.5186 - val_accuracy: 0.9062\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4379 - accuracy: 0.9091 - val_loss: 0.3977 - val_accuracy: 0.9375\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4131 - accuracy: 0.9141 - val_loss: 0.3774 - val_accuracy: 0.9062\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.9192 - val_loss: 0.3037 - val_accuracy: 0.9688\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.9293 - val_loss: 0.2819 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3967 - accuracy: 0.9293 - val_loss: 0.3195 - val_accuracy: 0.9375\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.9141 - val_loss: 0.2858 - val_accuracy: 0.9688\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3792 - accuracy: 0.9545 - val_loss: 0.3939 - val_accuracy: 0.9375\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3734 - accuracy: 0.9545 - val_loss: 0.3078 - val_accuracy: 0.9688\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3700 - accuracy: 0.9343 - val_loss: 0.3911 - val_accuracy: 0.9062\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3801 - accuracy: 0.9444 - val_loss: 0.2397 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3878 - accuracy: 0.9192 - val_loss: 0.3626 - val_accuracy: 0.9375\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3947 - accuracy: 0.9375 - val_loss: 0.3251 - val_accuracy: 0.9688\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4138 - accuracy: 0.9293 - val_loss: 0.2489 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3870 - accuracy: 0.9394 - val_loss: 0.4088 - val_accuracy: 0.9375\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 0.9330 - val_loss: 0.3513 - val_accuracy: 0.9375\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3728 - accuracy: 0.9293 - val_loss: 0.2416 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.9343 - val_loss: 0.2577 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3591 - accuracy: 0.9545 - val_loss: 0.4476 - val_accuracy: 0.9375\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3615 - accuracy: 0.9545 - val_loss: 0.3573 - val_accuracy: 0.9688\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.9242 - val_loss: 0.3831 - val_accuracy: 0.9375\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3788 - accuracy: 0.9242 - val_loss: 0.3871 - val_accuracy: 0.9062\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4247 - accuracy: 0.9192 - val_loss: 0.3075 - val_accuracy: 0.9375\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3870 - accuracy: 0.9343 - val_loss: 0.2514 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3892 - accuracy: 0.9444 - val_loss: 0.2977 - val_accuracy: 0.9375\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4250 - accuracy: 0.9192 - val_loss: 0.2877 - val_accuracy: 0.9375\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3675 - accuracy: 0.9420 - val_loss: 0.2893 - val_accuracy: 0.9688\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3729 - accuracy: 0.9444 - val_loss: 0.2496 - val_accuracy: 0.9688\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.9444 - val_loss: 0.2677 - val_accuracy: 0.9688\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4043 - accuracy: 0.9343 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3143 - accuracy: 0.9646 - val_loss: 0.2970 - val_accuracy: 0.9688\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3487 - accuracy: 0.9545 - val_loss: 0.3543 - val_accuracy: 0.9375\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.9545 - val_loss: 0.3111 - val_accuracy: 0.9688\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3498 - accuracy: 0.9330 - val_loss: 0.2468 - val_accuracy: 0.9688\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3585 - accuracy: 0.9444 - val_loss: 0.3556 - val_accuracy: 0.9375\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3585 - accuracy: 0.9343 - val_loss: 0.2777 - val_accuracy: 0.9688\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3584 - accuracy: 0.9444 - val_loss: 0.2943 - val_accuracy: 0.9688\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3132 - accuracy: 0.9596 - val_loss: 0.2811 - val_accuracy: 0.9688\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3412 - accuracy: 0.9596 - val_loss: 0.2936 - val_accuracy: 0.9688\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.9091 - val_loss: 0.2978 - val_accuracy: 0.9688\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4239 - accuracy: 0.9091 - val_loss: 0.5980 - val_accuracy: 0.8750\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.9394 - val_loss: 0.2756 - val_accuracy: 0.9688\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3481 - accuracy: 0.9495 - val_loss: 0.4159 - val_accuracy: 0.8750\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3597 - accuracy: 0.9545 - val_loss: 0.3499 - val_accuracy: 0.9375\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3559 - accuracy: 0.9394 - val_loss: 0.2874 - val_accuracy: 0.9688\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.9286 - val_loss: 0.2130 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f45c5714970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "img_width, img_height = 30, 30\n",
    "batch_size = 32\n",
    "\n",
    "# Define a simple CNN model\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(128, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(6, activation='softmax')  # Assuming 3 classes\n",
    "# ])\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu',kernel_regularizer=l1(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')  # Assuming 3 classes\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, \n",
    "    horizontal_flip=True,  # Enable horizontal flip\n",
    "    rotation_range=90# \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/bule/projects/Dice/workspace/data/single_dices/trainset',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Specify grayscale images\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    '/home/bule/projects/Dice/workspace/data/single_dices/trainset',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  # Specify grayscale images\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=200  # Adjust the number of epochs according to your needs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "[[9.9958140e-01 2.7688311e-05 3.9097472e-04 4.8002461e-12 6.2728878e-10\n",
      "  1.9545752e-11]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_prediction(model, file_path):\n",
    "    # Load the image file, converting it to a numpy array\n",
    "    img = image.load_img(file_path, target_size=(img_width, img_height), color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    # Rescale the image (as we did for the training images)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Add a new axis to make the image array compatible with the model (expects a batch)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make the prediction\n",
    "    prediction = model.predict(img_array)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Usage\n",
    "# model should be the trained model you want to use for prediction\n",
    "# '/path/to/image.png' should be the path to the image you want to predict\n",
    "\n",
    "img_path = \"/home/bule/projects/Dice/data/single_dices/single_dices/dice_classes/1/dice25.png\"\n",
    "img = cv2.imread(img_path)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "prediction = make_prediction(model, img_path)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq0qtty1e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpq0qtty1e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted to TensorFlow Lite and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 19:38:39.640056: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-04 19:38:39.640069: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-04 19:38:39.640218: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpq0qtty1e\n",
      "2023-11-04 19:38:39.640958: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-04 19:38:39.640963: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpq0qtty1e\n",
      "2023-11-04 19:38:39.642671: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2023-11-04 19:38:39.643204: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-04 19:38:39.670406: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpq0qtty1e\n",
      "2023-11-04 19:38:39.677270: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 37052 microseconds.\n",
      "2023-11-04 19:38:39.685690: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('model_single_dices.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model converted to TensorFlow Lite and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Augmented testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:14:15.373251: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-29 11:14:15.374494: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-29 11:14:15.391870: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 11:14:15.391888: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 11:14:15.391900: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 11:14:15.395259: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-29 11:14:15.395534: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 11:14:15.730470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Assuming you have a root directory where each subdirectory represents a class\n",
    "root_dir = \"/home/bule/projects/Dice/workspace/data/single_dices/testset\" \n",
    "save_dir = \"/home/bule/projects/Dice/workspace/data/single_dices/augmented_testset\"\n",
    "\n",
    "\n",
    "# Ensure the save directory exists\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Define image data generator with rotations\n",
    "datagen = ImageDataGenerator(rotation_range=360,  fill_mode='constant',cval=0)\n",
    "\n",
    "# Function to add noise to an image\n",
    "import numpy as np\n",
    "\n",
    "def add_noise(img):\n",
    "    img = img.astype('float32')\n",
    "\n",
    "    original_shape = img.shape  # Store the original shape\n",
    "    flattened_img = img.flatten()\n",
    "    noise = np.random.normal(loc=10.0, scale=1, size=flattened_img.shape)\n",
    "    noisy_flattened_img = flattened_img + noise\n",
    "\n",
    "    noisy_img = noisy_flattened_img.reshape(original_shape)\n",
    "\n",
    "    noisy_img = np.clip(noisy_img, 0, 255)\n",
    "    \n",
    "    return noisy_img\n",
    "\n",
    "\n",
    "# Function to process and save images from a directory\n",
    "def process_and_save_images_from_directory(class_dir,save_dir):\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            # Load image\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "            img = load_img(img_path)\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array.reshape((1,) + img_array.shape)\n",
    "            # # Apply rotation augmentation and add noise\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img_array, batch_size=1, save_to_dir=save_dir, save_prefix='aug', save_format='png'):\n",
    "                # Add noise\n",
    "                noisy_image = add_noise(batch[0])\n",
    "                noisy_image = array_to_img(noisy_image)\n",
    "\n",
    "                # Save the noisy image\n",
    "                noisy_image.save(os.path.join(save_dir, f'noisy_{i}_{filename}'))\n",
    "                \n",
    "                i += 1\n",
    "                if i >= 2:  # Decide how many augmented images you want per original image\n",
    "                    break\n",
    "\n",
    "\n",
    "# Change this to the path of your dataset\n",
    "for class_name in os.listdir(root_dir):\n",
    "    print(class_name)\n",
    "    class_dir = os.path.join(root_dir, class_name)\n",
    "    target_class_dir = os.path.join(save_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        process_and_save_images_from_directory(class_dir,target_class_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
